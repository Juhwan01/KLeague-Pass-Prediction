{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2: LSTM with Enhanced Features\n",
    "\n",
    "## 주요 개선사항\n",
    "- ✅ 추가 피처 엔지니어링\n",
    "  - 누적 이동량 (cumsum_delta_x, cumsum_delta_y)\n",
    "  - 패스 거리 (distance)\n",
    "  - 시퀀스 통계 (평균 위치, 표준편차)\n",
    "  - 진행률 (progress)\n",
    "- ✅ 입력 차원 확장: 2 → 8\n",
    "- ✅ Dropout 추가 (과적합 방지)\n",
    "- ✅ Epochs 증가: 5 → 20\n",
    "\n",
    "## 기대 효과\n",
    "- Baseline (V1): ~17.79m\n",
    "- Target (V2): ~15-16m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "print(\"✅ 라이브러리 로드 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 하이퍼파라미터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"./open_track1/train.csv\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20  # 5 → 20으로 증가\n",
    "LR = 1e-3\n",
    "HIDDEN_DIM = 128  # 64 → 128로 증가\n",
    "DROPOUT = 0.0  # Dropout 추가\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Using device:\", DEVICE)\n",
    "print(f\"Hyperparameters:\")\n",
    "print(f\"  - Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  - Epochs: {EPOCHS}\")\n",
    "print(f\"  - Learning Rate: {LR}\")\n",
    "print(f\"  - Hidden Dim: {HIDDEN_DIM}\")\n",
    "print(f\"  - Dropout: {DROPOUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 데이터 로드 및 피처 엔지니어링\n",
    "\n",
    "### 추가된 피처:\n",
    "1. **좌표**: start_x, start_y (정규화)\n",
    "2. **누적 이동량**: cumsum_delta_x, cumsum_delta_y\n",
    "3. **패스 거리**: distance\n",
    "4. **진행률**: progress (0~1)\n",
    "5. **평균 위치**: mean_x, mean_y\n",
    "6. **위치 표준편차**: std_x, std_y\n",
    "\n",
    "**총 입력 차원: 10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 피처 엔지니어링 함수 정의 ---\n",
    "def make_features(g):\n",
    "    sx = g[\"start_x\"].values / 105.0\n",
    "    sy = g[\"start_y\"].values / 68.0\n",
    "    ex = g[\"end_x\"].values / 105.0\n",
    "    ey = g[\"end_y\"].values / 68.0\n",
    "\n",
    "    delta_x = g[\"end_x\"].values - g[\"start_x\"].values\n",
    "    delta_y = g[\"end_y\"].values - g[\"start_y\"].values\n",
    "    cumsum_delta_x = np.cumsum(delta_x) / 105.0\n",
    "    cumsum_delta_y = np.cumsum(delta_y) / 68.0\n",
    "    diagonal = np.sqrt(105**2 + 68**2)\n",
    "    distance = np.sqrt(delta_x**2 + delta_y**2) / diagonal\n",
    "    mean_x = np.cumsum(sx) / (np.arange(len(sx)) + 1)\n",
    "    mean_y = np.cumsum(sy) / (np.arange(len(sy)) + 1)\n",
    "    n = len(g)\n",
    "    progress = np.arange(n) / max(n - 1, 1)\n",
    "\n",
    "    features = []\n",
    "    for i in range(len(g)):\n",
    "        feat = [\n",
    "            sx[i], sy[i],\n",
    "            cumsum_delta_x[i],\n",
    "            cumsum_delta_y[i],\n",
    "            distance[i],\n",
    "            progress[i],\n",
    "            mean_x[i],\n",
    "            mean_y[i],\n",
    "        ]\n",
    "        features.append(feat)\n",
    "        if i < len(g) - 1:\n",
    "            feat_end = [\n",
    "                ex[i], ey[i],\n",
    "                cumsum_delta_x[i],\n",
    "                cumsum_delta_y[i],\n",
    "                distance[i],\n",
    "                progress[i],\n",
    "                mean_x[i],\n",
    "                mean_y[i],\n",
    "            ]\n",
    "            features.append(feat_end)\n",
    "    return np.array(features, dtype=\"float32\")\n",
    "\n",
    "# --- 학습/검증 데이터 생성 ---\n",
    "episodes = []\n",
    "targets = []\n",
    "print(\"피처 엔지니어링 시작...\")\n",
    "for _, g in tqdm(df.groupby(\"game_episode\"), desc=\"Processing episodes\"):\n",
    "    g = g.reset_index(drop=True)\n",
    "    if len(g) < 2:\n",
    "        continue\n",
    "    seq = make_features(g)\n",
    "    ex = g[\"end_x\"].values / 105.0\n",
    "    ey = g[\"end_y\"].values / 68.0\n",
    "    target = np.array([ex[-1], ey[-1]], dtype=\"float32\")\n",
    "    episodes.append(seq)\n",
    "    targets.append(target)\n",
    "print(f\"\\n✅ 피처 엔지니어링 완료!\")\n",
    "print(f\"에피소드 수: {len(episodes):,}\")\n",
    "print(f\"입력 차원: {episodes[0].shape[1]}\")\n",
    "print(f\"샘플 시퀀스 길이: {episodes[0].shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Custom Dataset / DataLoader 정의 및 Validation 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpisodeDataset(Dataset):\n",
    "    def __init__(self, episodes, targets):\n",
    "        self.episodes = episodes\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.episodes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = torch.tensor(self.episodes[idx])   # [T, features]\n",
    "        tgt = torch.tensor(self.targets[idx])    # [2]\n",
    "        length = seq.size(0)\n",
    "        return seq, length, tgt\n",
    "\n",
    "def collate_fn(batch):\n",
    "    seqs, lengths, tgts = zip(*batch)\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "    padded = pad_sequence(seqs, batch_first=True)  # [B, T, features]\n",
    "    tgts = torch.stack(tgts, dim=0)                # [B, 2]\n",
    "    return padded, lengths, tgts\n",
    "\n",
    "# 에피소드 단위 train / valid split\n",
    "idx_train, idx_valid = train_test_split(\n",
    "    np.arange(len(episodes)), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "episodes_train = [episodes[i] for i in idx_train]\n",
    "targets_train  = [targets[i]  for i in idx_train]\n",
    "episodes_valid = [episodes[i] for i in idx_valid]\n",
    "targets_valid  = [targets[i]  for i in idx_valid]\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    EpisodeDataset(episodes_train, targets_train),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    EpisodeDataset(episodes_valid, targets_valid),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "print(f\"Train episodes: {len(episodes_train):,}\")\n",
    "print(f\"Valid episodes: {len(episodes_valid):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LSTM 모델 정의 (Enhanced Version)\n",
    "\n",
    "### 개선사항:\n",
    "- 입력 차원 확장 (2 → 8)\n",
    "- Hidden dimension 증가 (64 → 128)\n",
    "- Dropout 추가 (0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMEnhanced(nn.Module):\n",
    "    def __init__(self, input_dim=8, hidden_dim=128, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            dropout=0 if dropout == 0 else dropout,  # 1-layer면 dropout 무시\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 2)  # (x_norm, y_norm)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # x: [B, T, features], lengths: [B]\n",
    "        packed = pack_padded_sequence(\n",
    "            x, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        _, (h_n, _) = self.lstm(packed)\n",
    "        h_last = h_n[-1]           # [B, H] 마지막 layer의 hidden state\n",
    "        h_last = self.dropout(h_last)\n",
    "        out = self.fc(h_last)      # [B, 2]\n",
    "        return out\n",
    "\n",
    "# 입력 차원 자동 감지\n",
    "input_dim = episodes[0].shape[1]\n",
    "model = LSTMEnhanced(input_dim=input_dim, hidden_dim=HIDDEN_DIM, dropout=DROPOUT).to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "print(f\"\\n✅ 모델 생성 완료!\")\n",
    "print(f\"Input Dim: {input_dim}\")\n",
    "print(f\"Hidden Dim: {HIDDEN_DIM}\")\n",
    "print(f\"Output Dim: 2\")\n",
    "print(f\"\\n모델 구조:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dist = float(\"inf\")\n",
    "best_model_state = None\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'valid_dist': []\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"학습 시작\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # --- Train ---\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for X, lengths, y in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} [Train]\"):\n",
    "        X, lengths, y = X.to(DEVICE), lengths.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X, lengths)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "\n",
    "    train_loss = total_loss / len(train_loader.dataset)\n",
    "\n",
    "    # --- Valid: 평균 유클리드 거리 ---\n",
    "    model.eval()\n",
    "    dists = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, lengths, y in tqdm(valid_loader, desc=f\"Epoch {epoch}/{EPOCHS} [Valid]\"):\n",
    "            X, lengths, y = X.to(DEVICE), lengths.to(DEVICE), y.to(DEVICE)\n",
    "            pred = model(X, lengths)\n",
    "\n",
    "            pred_np = pred.cpu().numpy()\n",
    "            true_np = y.cpu().numpy()\n",
    "\n",
    "            pred_x = pred_np[:, 0] * 105.0\n",
    "            pred_y = pred_np[:, 1] * 68.0\n",
    "            true_x = true_np[:, 0] * 105.0\n",
    "            true_y = true_np[:, 1] * 68.0\n",
    "\n",
    "            dist = np.sqrt((pred_x - true_x) ** 2 + (pred_y - true_y) ** 2)\n",
    "            dists.append(dist)\n",
    "\n",
    "    mean_dist = np.concatenate(dists).mean()  # 평균 유클리드 거리\n",
    "    \n",
    "    # History 저장\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['valid_dist'].append(mean_dist)\n",
    "\n",
    "    print(\n",
    "        f\"[Epoch {epoch:2d}/{EPOCHS}] \"\n",
    "        f\"train_loss={train_loss:.4f} | \"\n",
    "        f\"valid_mean_dist={mean_dist:.4f}\"\n",
    "    )\n",
    "\n",
    "    # ----- BEST MODEL 업데이트 -----\n",
    "    if mean_dist < best_dist:\n",
    "        best_dist = mean_dist\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\" --> ✨ Best model updated! (dist={best_dist:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"✅ 학습 완료!\")\n",
    "print(f\"Best Validation Distance: {best_dist:.4f}m\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 학습 곡선 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Train Loss\n",
    "axes[0].plot(range(1, EPOCHS+1), history['train_loss'], marker='o')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Train Loss (MSE)')\n",
    "axes[0].set_title('Training Loss Curve')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Valid Distance\n",
    "axes[1].plot(range(1, EPOCHS+1), history['valid_dist'], marker='o', color='red')\n",
    "axes[1].axhline(best_dist, color='green', linestyle='--', label=f'Best: {best_dist:.4f}m')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Validation Mean Distance (m)')\n",
    "axes[1].set_title('Validation Distance Curve')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 평가 데이터셋 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 추론(테스트)도 동일 함수 사용 ---\n",
    "preds_x = []\n",
    "preds_y = []\n",
    "for _, row in tqdm(submission.iterrows(), total=len(submission), desc=\"Inference\"):\n",
    "    file_path = row[\"path\"].replace(\"./test/\", \"./open_track1/test/\")\n",
    "    g = pd.read_csv(file_path).reset_index(drop=True)\n",
    "    seq = make_features(g)\n",
    "    x = torch.tensor(seq).unsqueeze(0).to(DEVICE)\n",
    "    length = torch.tensor([seq.shape[0]]).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        pred = model(x, length).cpu().numpy()[0]\n",
    "    preds_x.append(pred[0] * 105.0)\n",
    "    preds_y.append(pred[1] * 68.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 제출 Submission 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"end_x\"] = preds_x\n",
    "submission[\"end_y\"] = preds_y\n",
    "submission[[\"game_episode\", \"end_x\", \"end_y\"]].to_csv(\"./v2_submit.csv\", index=False)\n",
    "\n",
    "print(\"✅ 제출 파일 저장 완료: v2_submit.csv\")\n",
    "print(\"\\n[제출 파일 샘플]\")\n",
    "display(submission[[\"game_episode\", \"end_x\", \"end_y\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 성능 비교\n",
    "\n",
    "### Baseline (V1) vs Enhanced (V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"성능 비교\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n[Baseline V1]\")\n",
    "print(\"  - 입력 차원: 2 (x, y 좌표만)\")\n",
    "print(\"  - Hidden Dim: 64\")\n",
    "print(\"  - Epochs: 5\")\n",
    "print(\"  - Valid Distance: ~17.79m\")\n",
    "\n",
    "print(\"\\n[Enhanced V2]\")\n",
    "print(f\"  - 입력 차원: {input_dim} (좌표 + 누적 이동 + 거리 + 진행률 + 통계)\")\n",
    "print(f\"  - Hidden Dim: {HIDDEN_DIM}\")\n",
    "print(f\"  - Epochs: {EPOCHS}\")\n",
    "print(f\"  - Dropout: {DROPOUT}\")\n",
    "print(f\"  - Valid Distance: {best_dist:.4f}m\")\n",
    "\n",
    "improvement = 17.79 - best_dist\n",
    "improvement_pct = (improvement / 17.79) * 100\n",
    "\n",
    "print(\"\\n[개선도]\")\n",
    "print(f\"  - 절대 개선: {improvement:.4f}m\")\n",
    "print(f\"  - 상대 개선: {improvement_pct:.2f}%\")\n",
    "\n",
    "if best_dist < 17.79:\n",
    "    print(\"\\n✅ V2가 V1보다 성능이 우수합니다!\")\n",
    "else:\n",
    "    print(\"\\n⚠️ V2가 V1보다 성능이 낮습니다. 하이퍼파라미터 조정이 필요합니다.\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
